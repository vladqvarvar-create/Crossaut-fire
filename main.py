import os
import logging
import tempfile
import subprocess
import requests
import json
import wave
from typing import Optional, Dict
import telebot
from telebot.types import Message, Voice, Audio, VideoNote

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class SpeechRecognitionBot:
    def __init__(self, token: str):
        self.bot = telebot.TeleBot(token)
        self.setup_handlers()
        
        self.whisper_token = os.getenv('HUGGINGFACE_TOKEN', '')
        logger.info("ü§ñ –ë–æ—Ç —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ!")

    def setup_handlers(self):
        @self.bot.message_handler(commands=['start', 'help'])
        def send_welcome(message: Message):
            welcome_text = """
üé§ –ë–æ—Ç –¥–ª—è –†–ï–ê–õ–¨–ù–û–ì–û —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –≥–æ–ª–æ—Å—É

üìå –ù–∞–¥—Å–∏–ª–∞–π—Ç–µ –≥–æ–ª–æ—Å–æ–≤—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
üåç –ú–æ–≤–∏: –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞, –†–æ—Å—ñ–π—Å—å–∫–∞, –ê–Ω–≥–ª—ñ–π—Å—å–∫–∞
üöÄ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î Whisper AI
            """
            self.bot.reply_to(message, welcome_text)

        @self.bot.message_handler(content_types=['voice'])
        def handle_voice(message: Message):
            self.process_audio_message(message, message.voice)

    def download_file(self, file_id: str) -> Optional[str]:
        try:
            file_info = self.bot.get_file(file_id)
            downloaded_file = self.bot.download_file(file_info.file_path)
            
            with tempfile.NamedTemporaryFile(delete=False, suffix='.ogg') as temp_file:
                temp_file.write(downloaded_file)
                return temp_file.name
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {e}")
            return None

    def convert_to_wav(self, input_path: str) -> Optional[str]:
        try:
            output_path = input_path + '.wav'
            cmd = [
                'ffmpeg', '-i', input_path,
                '-acodec', 'pcm_s16le', '-ac', '1', '-ar', '16000',
                '-y', output_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
            if result.returncode == 0:
                return output_path
            else:
                logger.error(f"FFmpeg –ø–æ–º–∏–ª–∫–∞: {result.stderr}")
                return None
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó: {e}")
            return None

    def recognize_with_whisper_api(self, audio_path: str) -> Optional[str]:
        """–†–µ–∞–ª—å–Ω–µ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —á–µ—Ä–µ–∑ Whisper API"""
        try:
            if not self.whisper_token:
                logger.warning("‚ùå Whisper —Ç–æ–∫–µ–Ω –Ω–µ –≤–∫–∞–∑–∞–Ω–æ")
                return None

            API_URL = "https://api-inference.huggingface.co/models/openai/whisper-large-v3"
            
            headers = {"Authorization": f"Bearer {self.whisper_token}"}
            
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —Ñ–∞–π–ª —ñ—Å–Ω—É—î —ñ –Ω–µ –ø–æ—Ä–æ–∂–Ω—ñ–π
            if not os.path.exists(audio_path) or os.path.getsize(audio_path) == 0:
                logger.error("‚ùå –ê—É–¥—ñ–æ —Ñ–∞–π–ª –Ω–µ —ñ—Å–Ω—É—î –∞–±–æ –ø–æ—Ä–æ–∂–Ω—ñ–π")
                return None
            
            with open(audio_path, "rb") as f:
                data = f.read()
            
            logger.info("üì° –ù–∞–¥—Å–∏–ª–∞–Ω–Ω—è –¥–æ Whisper API...")
            response = requests.post(API_URL, headers=headers, data=data, timeout=60)
            
            logger.info(f"üîî Whisper —Å—Ç–∞—Ç—É—Å: {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                text = result.get('text', '').strip()
                if text and len(text) > 1:  # –ó–º–µ–Ω—à–∏–º–æ –º—ñ–Ω—ñ–º–∞–ª—å–Ω—É –¥–æ–≤–∂–∏–Ω—É —Ç–µ–∫—Å—Ç—É
                    logger.info(f"‚úÖ Whisper —É—Å–ø—ñ—à–Ω–æ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤ —Ç–µ–∫—Å—Ç: {text[:50]}...")
                    return text
                else:
                    logger.warning("‚ùå Whisper –ø–æ–≤–µ—Ä–Ω—É–≤ –ø–æ—Ä–æ–∂–Ω—ñ–π —Ç–µ–∫—Å—Ç")
                    return None
                    
            elif response.status_code == 503:
                # –ú–æ–¥–µ–ª—å –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î—Ç—å—Å—è
                error_info = response.json().get('error', '')
                logger.warning(f"‚è≥ –ú–æ–¥–µ–ª—å –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î—Ç—å—Å—è: {error_info}")
                return None
                
            else:
                error_text = response.text[:500] if response.text else "–ù–µ–º–∞—î –¥–µ—Ç–∞–ª–µ–π"
                logger.error(f"‚ùå Whisper –ø–æ–º–∏–ª–∫–∞ {response.status_code}: {error_text}")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–ø–∏—Ç—É –¥–æ Whisper: {e}")
            return None

    def get_audio_info(self, audio_path: str) -> Dict[str, any]:
        """–û—Ç—Ä–∏–º–∞–Ω–Ω—è —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –ø—Ä–æ –∞—É–¥—ñ–æ"""
        try:
            with wave.open(audio_path, 'rb') as wav_file:
                frames = wav_file.getnframes()
                rate = wav_file.getframerate()
                duration = frames / float(rate)
                
                return {
                    'duration': duration,
                    'sample_rate': rate,
                    'channels': wav_file.getnchannels(),
                    'frames': frames
                }
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –∞–Ω–∞–ª—ñ–∑—É –∞—É–¥—ñ–æ: {e}")
            return {'duration': 0, 'sample_rate': 0, 'channels': 0, 'frames': 0}

    def recognize_speech(self, audio_path: str) -> Dict[str, str]:
        """–û—Å–Ω–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è"""
        logger.info("üîç –ü–æ—á–∞—Ç–æ–∫ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è...")
        
        # –û—Ç—Ä–∏–º—É—î–º–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –∞—É–¥—ñ–æ
        audio_info = self.get_audio_info(audio_path)
        logger.info(f"üìä –ê—É–¥—ñ–æ: {audio_info['duration']:.1f}—Å, {audio_info['sample_rate']}Hz")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å –∞—É–¥—ñ–æ
        if audio_info['duration'] < 0.5:
            return {
                '–ü–æ–º–∏–ª–∫–∞': "‚ùå –ê—É–¥—ñ–æ –∑–∞–Ω–∞–¥—Ç–æ –∫–æ—Ä–æ—Ç–∫–µ (–º–µ–Ω—à–µ 0.5 —Å–µ–∫—É–Ω–¥–∏)"
            }
        
        # 1. –°–ø—Ä–æ–±–∞ Whisper API
        if self.whisper_token:
            text = self.recognize_with_whisper_api(audio_path)
            if text:
                return {'Whisper AI': text}
        
        # 2. –Ø–∫—â–æ Whisper –Ω–µ —Å–ø—Ä–∞—Ü—é–≤–∞–≤
        if audio_info['duration'] > 0:
            return {
                '–Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è': f"""üîä –ê—É–¥—ñ–æ –∞–Ω–∞–ª—ñ–∑:
‚Ä¢ –¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å: {audio_info['duration']:.1f} —Å–µ–∫—É–Ω–¥
‚Ä¢ –ß–∞—Å—Ç–æ—Ç–∞: {audio_info['sample_rate']} Hz
‚Ä¢ –ö–∞–Ω–∞–ª–∏: {audio_info['channels']}

‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ –º–æ–≤—É.

üí° –ú–æ–∂–ª–∏–≤—ñ –ø—Ä–∏—á–∏–Ω–∏:
‚Ä¢ Whisper API —Ç–∏–º—á–∞—Å–æ–≤–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π
‚Ä¢ –ú–æ–¥–µ–ª—å –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î—Ç—å—Å—è (–∑–∞—á–µ–∫–∞–π—Ç–µ 20-30 —Å–µ–∫)
‚Ä¢ –ü—Ä–æ–±–ª–µ–º–∏ –∑ —ñ–Ω—Ç–µ—Ä–Ω–µ—Ç-–∑'—î–¥–Ω–∞–Ω–Ω—è–º
‚Ä¢ –ê—É–¥—ñ–æ –∑–∞–Ω–∞–¥—Ç–æ –∫–æ—Ä–æ—Ç–∫–µ –∞–±–æ —Ç–∏—Ö–µ

üîÑ –°–ø—Ä–æ–±—É–π—Ç–µ —â–µ —Ä–∞–∑ —á–µ—Ä–µ–∑ –¥–µ–∫—ñ–ª—å–∫–∞ —Ö–≤–∏–ª–∏–Ω."""
            }
        else:
            return {
                '–ü–æ–º–∏–ª–∫–∞': "‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –æ–±—Ä–æ–±–∏—Ç–∏ –∞—É–¥—ñ–æ —Ñ–∞–π–ª. –°–ø—Ä–æ–±—É–π—Ç–µ —ñ–Ω—à–µ –≥–æ–ª–æ—Å–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è."
            }

    def combine_results(self, results: Dict[str, str]) -> str:
        if not results:
            return "‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –æ–±—Ä–æ–±–∏—Ç–∏ –∞—É–¥—ñ–æ."
        
        if '–ü–æ–º–∏–ª–∫–∞' in results:
            return results['–ü–æ–º–∏–ª–∫–∞']
            
        if '–Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è' in results:
            return results['–Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è']
        
        # –†–µ–∞–ª—å–Ω–∏–π —Ä–æ–∑–ø—ñ–∑–Ω–∞–Ω–∏–π —Ç–µ–∫—Å—Ç
        combined_text = "üé§ **–¢–ï–ö–°–¢ –†–û–ó–ü–Ü–ó–ù–ê–ù–û –ó –ì–û–õ–û–°–£:**\n\n"
        
        for service, text in results.items():
            combined_text += f"**{service}:**\n"
            combined_text += f"{text}\n\n"
        
        combined_text += "‚úÖ –ì–æ–ª–æ—Å —É—Å–ø—ñ—à–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–æ–≤–∞–Ω–æ –≤ —Ç–µ–∫—Å—Ç!"
        return combined_text

    def process_audio_message(self, message: Message, file_obj):
        processing_msg = self.bot.reply_to(message, "üîç –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∞—É–¥—ñ–æ...")
        
        temp_file, wav_file = None, None
        
        try:
            # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
            temp_file = self.download_file(file_obj.file_id)
            if not temp_file:
                self.bot.edit_message_text("‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è", message.chat.id, processing_msg.message_id)
                return

            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è
            self.bot.edit_message_text("üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –∞—É–¥—ñ–æ...", message.chat.id, processing_msg.message_id)
            wav_file = self.convert_to_wav(temp_file)
            if not wav_file:
                self.bot.edit_message_text("‚ùå –ü–æ–º–∏–ª–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó", message.chat.id, processing_msg.message_id)
                return

            # –†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è
            self.bot.edit_message_text("üé§ –†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –º–æ–≤–∏...", message.chat.id, processing_msg.message_id)
            results = self.recognize_speech(wav_file)
            combined_text = self.combine_results(results)

            # –†–µ–∑—É–ª—å—Ç–∞—Ç
            self.bot.edit_message_text(combined_text, message.chat.id, processing_msg.message_id)
            logger.info("‚úÖ –û–±—Ä–æ–±–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
            self.bot.edit_message_text("‚ùå –ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏", message.chat.id, processing_msg.message_id)
        finally:
            self.cleanup_files(temp_file, wav_file)

    def cleanup_files(self, *files):
        for file_path in files:
            try:
                if file_path and os.path.exists(file_path):
                    os.unlink(file_path)
            except Exception as e:
                logger.error(f"–ü–æ–º–∏–ª–∫–∞ –≤–∏–¥–∞–ª–µ–Ω–Ω—è: {e}")

    def run(self):
        """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ –±–µ–∑ Flask"""
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞...")
        try:
            self.bot.infinity_polling(timeout=90, long_polling_timeout=90)
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞: {e}")
            import time
            time.sleep(10)
            logger.info("üîÑ –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –±–æ—Ç–∞...")
            self.run()

def main():
    token = os.getenv('TELEGRAM_BOT_TOKEN')
    if not token:
        logger.error("‚ùå –ù–µ–º–∞—î TELEGRAM_BOT_TOKEN")
        return

    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Ç–æ–∫–µ–Ω Whisper
    whisper_token = os.getenv('HUGGINGFACE_TOKEN', '')
    if whisper_token:
        logger.info("‚úÖ Whisper —Ç–æ–∫–µ–Ω –∑–Ω–∞–π–¥–µ–Ω–æ")
    else:
        logger.warning("‚ö†Ô∏è Whisper —Ç–æ–∫–µ–Ω –Ω–µ –≤–∫–∞–∑–∞–Ω–æ, —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –º–æ–∂–µ –Ω–µ –ø—Ä–∞—Ü—é–≤–∞—Ç–∏")

    bot = SpeechRecognitionBot(token)
    bot.run()

if __name__ == '__main__':
    main()