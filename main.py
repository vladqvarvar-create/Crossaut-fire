import os
import logging
import tempfile
import subprocess
import requests
import random
from typing import Optional, Dict
import telebot
from telebot.types import Message, Voice, Audio, VideoNote
from flask import Flask

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = Flask(__name__)

@app.route('/')
def home():
    return "ü§ñ Telegram Speech Recognition Bot is running!"

class SpeechRecognitionBot:
    def __init__(self, token: str):
        self.bot = telebot.TeleBot(token)
        self.setup_handlers()
        
        self.languages = {
            'uk': {'name': '–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞', 'code': 'uk-UA'},
            'ru': {'name': '–†–æ—Å—ñ–π—Å—å–∫–∞', 'code': 'ru-RU'}, 
            'en': {'name': '–ê–Ω–≥–ª—ñ–π—Å—å–∫–∞', 'code': 'en-US'}
        }
        
        # –¢–æ–∫–µ–Ω –¥–ª—è Whisper (–æ–ø—Ü—ñ–π–Ω–æ)
        self.whisper_token = os.getenv('HUGGINGFACE_TOKEN', '')
        
        logger.info("ü§ñ –ë–æ—Ç –∑ —Ä–µ–∞–ª—å–Ω–∏–º —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è–º!")

    def setup_handlers(self):
        @self.bot.message_handler(commands=['start', 'help'])
        def send_welcome(message: Message):
            welcome_text = """
üé§ –ë–æ—Ç –¥–ª—è –†–ï–ê–õ–¨–ù–û–ì–û —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –≥–æ–ª–æ—Å—É

üìå –ù–∞–¥—Å–∏–ª–∞–π—Ç–µ –≥–æ–ª–æ—Å–æ–≤—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
üåç –ú–æ–≤–∏: UA, RU, EN
üöÄ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î Whisper AI —Ç–∞ Google Speech
            """
            self.bot.reply_to(message, welcome_text)

        @self.bot.message_handler(content_types=['voice'])
        def handle_voice(message: Message):
            self.process_audio_message(message, message.voice)

    def download_file(self, file_id: str) -> Optional[str]:
        try:
            file_info = self.bot.get_file(file_id)
            downloaded_file = self.bot.download_file(file_info.file_path)
            
            with tempfile.NamedTemporaryFile(delete=False, suffix='.ogg') as temp_file:
                temp_file.write(downloaded_file)
                return temp_file.name
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {e}")
            return None

    def convert_to_wav(self, input_path: str) -> Optional[str]:
        try:
            output_path = input_path + '.wav'
            cmd = [
                'ffmpeg', '-i', input_path,
                '-acodec', 'pcm_s16le', '-ac', '1', '-ar', '16000',
                '-y', output_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
            if result.returncode == 0:
                return output_path
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó: {e}")
        return None

    def recognize_with_whisper(self, audio_path: str) -> Optional[str]:
        """–†–µ–∞–ª—å–Ω–µ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —á–µ—Ä–µ–∑ Whisper API"""
        try:
            API_URL = "https://api-inference.huggingface.co/models/openai/whisper-large-v3"
            
            headers = {}
            if self.whisper_token:
                headers["Authorization"] = f"Bearer {self.whisper_token}"
            
            with open(audio_path, "rb") as f:
                data = f.read()
            
            response = requests.post(API_URL, headers=headers, data=data, timeout=60)
            
            if response.status_code == 200:
                result = response.json()
                text = result.get('text', '').strip()
                if text:
                    logger.info(f"Whisper —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤: {text[:100]}...")
                    return text
            else:
                logger.warning(f"Whisper API: {response.status_code}")
                
        except Exception as e:
            logger.error(f"Whisper –ø–æ–º–∏–ª–∫–∞: {e}")
        
        return None

    def recognize_with_google_speech(self, audio_path: str, language_code: str) -> Optional[str]:
        """–†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —á–µ—Ä–µ–∑ Google Speech"""
        try:
            import speech_recognition as sr
            
            recognizer = sr.Recognizer()
            
            with sr.AudioFile(audio_path) as source:
                # –ü–æ–∫—Ä–∞—â—É—î–º–æ —è–∫—ñ—Å—Ç—å –¥–ª—è –∫—Ä–∞—â–æ–≥–æ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è
                recognizer.adjust_for_ambient_noise(source, duration=0.5)
                audio_data = recognizer.record(source)
                
                text = recognizer.recognize_google(audio_data, language=language_code)
                if text:
                    logger.info(f"Google —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤: {text[:100]}...")
                    return text
                    
        except Exception as e:
            logger.warning(f"Google Speech –ø–æ–º–∏–ª–∫–∞: {e}")
        
        return None

    def recognize_speech(self, audio_path: str) -> Dict[str, str]:
        """–û—Å–Ω–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è"""
        results = {}
        
        logger.info("üîç –ü–æ—á–∞—Ç–æ–∫ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è...")
        
        # 1. –°–ø–µ—Ä—à—É –ø—Ä–æ–±—É—î–º–æ Whisper (–Ω–∞–π–∫—Ä–∞—â–∞ —è–∫—ñ—Å—Ç—å)
        text = self.recognize_with_whisper(audio_path)
        
        if text:
            results['Whisper AI'] = text
        else:
            # 2. –Ø–∫—â–æ Whisper –Ω–µ —Å–ø—Ä–∞—Ü—é–≤–∞–≤, –ø—Ä–æ–±—É—î–º–æ Google Speech –¥–ª—è –∫–æ–∂–Ω–æ—ó –º–æ–≤–∏
            for lang_code, lang_info in self.languages.items():
                text = self.recognize_with_google_speech(audio_path, lang_info['code'])
                if text:
                    results[lang_info['name']] = text
                    break
        
        # 3. –Ø–∫—â–æ –Ω—ñ—á–æ–≥–æ –Ω–µ —Å–ø—Ä–∞—Ü—é–≤–∞–ª–æ
        if not results:
            logger.error("‚ùå –ñ–æ–¥–µ–Ω —Å–µ—Ä–≤—ñ—Å –Ω–µ –∑–º—ñ–≥ —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ –º–æ–≤—É")
            results['–ü–æ–º–∏–ª–∫–∞'] = "–ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ –º–æ–≤—É. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ:\n‚Ä¢ –Ø–∫—ñ—Å—Ç—å –∞—É–¥—ñ–æ\n‚Ä¢ –ß–∏ –ø—ñ–¥—Ç—Ä–∏–º—É—î—Ç—å—Å—è –º–æ–≤–∞\n‚Ä¢ –Ü–Ω—Ç–µ—Ä–Ω–µ—Ç-–∑'—î–¥–Ω–∞–Ω–Ω—è"
        
        return results

    def combine_results(self, results: Dict[str, str]) -> str:
        if not results or '–ü–æ–º–∏–ª–∫–∞' in results:
            return f"‚ùå {results.get('–ü–æ–º–∏–ª–∫–∞', '–ü–æ–º–∏–ª–∫–∞ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è')}"
        
        combined_text = "üé§ **–¢–ï–ö–°–¢ –†–û–ó–ü–Ü–ó–ù–ê–ù–û –ó –ì–û–õ–û–°–£:**\n\n"
        
        for service, text in results.items():
            combined_text += f"**{service}:**\n"
            combined_text += f"{text}\n\n"
        
        return combined_text

    def process_audio_message(self, message: Message, file_obj):
        processing_msg = self.bot.reply_to(message, "üîç –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∞—É–¥—ñ–æ...")
        
        temp_file, wav_file = None, None
        
        try:
            # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
            temp_file = self.download_file(file_obj.file_id)
            if not temp_file:
                self.bot.edit_message_text("‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è", message.chat.id, processing_msg.message_id)
                return

            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è
            self.bot.edit_message_text("üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –∞—É–¥—ñ–æ...", message.chat.id, processing_msg.message_id)
            wav_file = self.convert_to_wav(temp_file)
            if not wav_file:
                self.bot.edit_message_text("‚ùå –ü–æ–º–∏–ª–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó", message.chat.id, processing_msg.message_id)
                return

            # –†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è
            self.bot.edit_message_text("üé§ –†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –º–æ–≤–∏...", message.chat.id, processing_msg.message_id)
            results = self.recognize_speech(wav_file)
            combined_text = self.combine_results(results)

            # –†–µ–∑—É–ª—å—Ç–∞—Ç
            self.bot.edit_message_text(combined_text, message.chat.id, processing_msg.message_id)
            logger.info("‚úÖ –£—Å–ø—ñ—à–Ω–µ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è")

        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
            self.bot.edit_message_text("‚ùå –ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏", message.chat.id, processing_msg.message_id)
        finally:
            self.cleanup_files(temp_file, wav_file)

    def cleanup_files(self, *files):
        for file_path in files:
            try:
                if file_path and os.path.exists(file_path):
                    os.unlink(file_path)
            except Exception as e:
                logger.error(f"–ü–æ–º–∏–ª–∫–∞ –≤–∏–¥–∞–ª–µ–Ω–Ω—è: {e}")

    def run_polling(self):
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞...")
        try:
            self.bot.infinity_polling(timeout=90, long_polling_timeout=90)
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞: {e}")
            import time
            time.sleep(10)
            self.run_polling()

def start_bot():
    token = os.getenv('TELEGRAM_BOT_TOKEN')
    if not token:
        logger.error("‚ùå –ù–µ–º–∞—î —Ç–æ–∫–µ–Ω—É")
        return None

    logger.info("‚úÖ –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞...")
    return SpeechRecognitionBot(token)

if __name__ == '__main__':
    bot_instance = start_bot()
    if bot_instance:
        port = int(os.environ.get('PORT', 10000))
        logger.info(f"üåê –ü–æ—Ä—Ç: {port}")
        
        import threading
        bot_thread = threading.Thread(target=bot_instance.run_polling)
        bot_thread.daemon = True
        bot_thread.start()
        
        app.run(host='0.0.0.0', port=port, debug=False)